"""
FinanceWorkflow with LLM - å¤šä»£ç†äººç†è²¡è«®è©¢å·¥ä½œæµç¨‹ (ä½¿ç”¨çœŸå¯¦ LLM)

å¯¦ä½œ Linus å“²å­¸ï¼š
1. å¥½å“å‘³ï¼šæ¸…æ™°çš„å·¥ä½œæµç¨‹ï¼Œæ¯å€‹ç¯€é»è·è²¬å–®ç´”
2. è³‡æ–™çµæ§‹å„ªå…ˆï¼šç‹€æ…‹é©…å‹•çš„å·¥ä½œæµç¨‹è¨­è¨ˆ
3. å¯¦ç”¨ä¸»ç¾©ï¼šå°ˆæ³¨è§£æ±ºå¯¦éš›ç†è²¡è«®è©¢éœ€æ±‚
4. ç°¡æ½”åŸ·å¿µï¼šé¿å…è¤‡é›œçš„æ¢ä»¶åˆ†æ”¯å’Œç‹€æ…‹è½‰æ›
"""

import asyncio
import logging
import uuid
from datetime import datetime
from typing import Any, Dict, List, Optional

from langgraph.graph import END, START, StateGraph

from ..agents import ManagerAgent
from ..agents.base_agent import AgentMessage, AgentType, MessageType
from ..agents.financial_analyst_agent_llm import FinancialAnalystAgentLLM
from ..agents.financial_planner_agent_llm import FinancialPlannerAgentLLM
from ..agents.legal_expert_agent_llm import LegalExpertAgentLLM
from ..database import PersonalFinanceDB
from ..llm import is_llm_configured
from ..rag import ChromaVectorStore, KnowledgeRetriever
from .state_manager import FinanceState, StateManager, WorkflowStatus

logger = logging.getLogger(__name__)


class FinanceWorkflowLLM:
    """ç†è²¡è«®è©¢å·¥ä½œæµç¨‹ (ä½¿ç”¨çœŸå¯¦ LLM)

    å·¥ä½œæµç¨‹ï¼š
    1. ä½¿ç”¨è€…æŸ¥è©¢ â†’ 2. è·¯ç”±åˆ†æ â†’ 3. å°ˆå®¶è™•ç† â†’ 4. å›æ‡‰æ•´åˆ â†’ 5. æœ€çµ‚å›æ‡‰

    æ‰€æœ‰ agents éƒ½ä½¿ç”¨ GPT-4o-mini æ¨¡å‹
    """

    def __init__(self):
        """åˆå§‹åŒ–ç†è²¡è«®è©¢å·¥ä½œæµç¨‹ (LLM ç‰ˆæœ¬)

        å»ºç«‹å°ˆå®¶ç³»çµ±æ¶æ§‹ï¼š
        - æ³•å¾‹å°ˆå®¶ï¼šç´” LLM é©…å‹•ï¼Œä¸ä½¿ç”¨ RAG
        - é‡‘è/ç†è²¡å°ˆå®¶ï¼šLLM + RAG ç³»çµ±ï¼Œä½¿ç”¨ä¸åŒ prompt
        """
        self.state_manager = StateManager()

        # åˆå§‹åŒ–å…±ç”¨ RAG ç³»çµ± (åƒ…ä¾›é‡‘èå’Œç†è²¡å°ˆå®¶ä½¿ç”¨)
        try:
            self.vector_store = ChromaVectorStore(collection_name="finance_knowledge_optimal")
            self.knowledge_retriever = KnowledgeRetriever(self.vector_store)
            logger.info("å…±ç”¨ RAG ç³»çµ±åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"RAG ç³»çµ±åˆå§‹åŒ–å¤±æ•—: {e}")
            self.knowledge_retriever = None

        # åˆå§‹åŒ–å€‹äººè²¡å‹™è³‡æ–™åº«
        try:
            self.personal_db = PersonalFinanceDB()
            logger.info("å€‹äººè²¡å‹™è³‡æ–™åº«é€£æ¥æˆåŠŸ")
        except Exception as e:
            logger.error(f"å€‹äººè²¡å‹™è³‡æ–™åº«é€£æ¥å¤±æ•—: {e}")
            self.personal_db = None

        # åˆå§‹åŒ– LLM å°ˆå®¶ä»£ç†äºº
        self._initialize_llm_agents()

        # å»ºç«‹ LangGraph å·¥ä½œæµç¨‹
        self._build_workflow()

    def _initialize_llm_agents(self):
        """åˆå§‹åŒ–ä½¿ç”¨ LLM çš„å°ˆå®¶ä»£ç†äºº"""
        try:
            # åˆå§‹åŒ–ç®¡ç†ä»£ç†äºº (ç”¨æ–¼è·¯ç”±)
            self.manager_agent = ManagerAgent()

            # åˆå§‹åŒ–ç†è²¡è¦åŠƒå°ˆå®¶ (ä½¿ç”¨ LLM + RAG + å€‹äººè³‡æ–™åº«)
            self.financial_planner = FinancialPlannerAgentLLM(
                name="ç†è²¡è¦åŠƒå°ˆå®¶",
                knowledge_retriever=self.knowledge_retriever,
                personal_db=self.personal_db
            )

            # åˆå§‹åŒ–é‡‘èåˆ†æå°ˆå®¶ (ä½¿ç”¨ LLM + RAG)
            self.financial_analyst = FinancialAnalystAgentLLM(
                name="é‡‘èåˆ†æå°ˆå®¶",
                knowledge_retriever=self.knowledge_retriever
            )

            # åˆå§‹åŒ–æ³•å¾‹å°ˆå®¶ (ç´” LLMï¼Œä¸ä½¿ç”¨ RAG)
            self.legal_expert = LegalExpertAgentLLM(
                name="æ³•å¾‹å°ˆå®¶"
            )

            # å°ˆå®¶æ˜ å°„
            self.experts = {
                AgentType.FINANCIAL_PLANNER: self.financial_planner,
                AgentType.FINANCIAL_ANALYST: self.financial_analyst,
                AgentType.LEGAL_EXPERT: self.legal_expert
            }

            # æª¢æŸ¥ LLM é…ç½®ç‹€æ…‹
            llm_status = "å·²é…ç½®" if is_llm_configured() else "ä½¿ç”¨æ¨¡æ“¬å›æ‡‰"
            logger.info(f"LLM å°ˆå®¶ä»£ç†äººåˆå§‹åŒ–å®Œæˆï¼ŒLLM ç‹€æ…‹: {llm_status}")

            # è¨˜éŒ„æ¯å€‹ agent çš„ç‹€æ…‹
            for agent_type, agent in self.experts.items():
                status = agent.get_llm_status()
                logger.info(f"{agent.name} - LLM: {status['llm_configured']}, æ¨¡å‹: {status['model']}")

        except Exception as e:
            logger.error(f"å°ˆå®¶ä»£ç†äººåˆå§‹åŒ–å¤±æ•—: {e}")
            raise

    def _build_workflow(self):
        """å»ºç«‹ LangGraph å·¥ä½œæµç¨‹"""
        # å»ºç«‹ç‹€æ…‹åœ–
        workflow = StateGraph(FinanceState)

        # æ·»åŠ ç¯€é»
        workflow.add_node("query_routing", self._route_query)
        workflow.add_node("expert_processing", self._process_experts)
        workflow.add_node("response_integration", self._integrate_responses)

        # å®šç¾©é‚Š
        workflow.add_edge(START, "query_routing")
        workflow.add_edge("query_routing", "expert_processing")
        workflow.add_edge("expert_processing", "response_integration")
        workflow.add_edge("response_integration", END)

        # ç·¨è­¯å·¥ä½œæµç¨‹
        self.workflow = workflow.compile()

    async def run(
        self,
        user_query: str,
        user_profile: Dict = None,
        session_id: str = None,
        conversation_history: List[Dict[str, str]] = None
    ) -> Dict:
        """åŸ·è¡Œç†è²¡è«®è©¢å·¥ä½œæµç¨‹

        Args:
            user_query: ä½¿ç”¨è€…æŸ¥è©¢
            user_profile: ä½¿ç”¨è€…è³‡æ–™
            session_id: æœƒè©± ID
            conversation_history: å°è©±æ­·å²ï¼ˆOpenAI æ ¼å¼ï¼‰

        Returns:
            å®Œæ•´çš„è«®è©¢çµæœ
        """
        session_id = session_id or str(uuid.uuid4())

        try:
            # åˆå§‹åŒ–ç‹€æ…‹
            initial_state = self.state_manager.create_initial_state(
                session_id=session_id,
                user_query=user_query,
                user_profile=user_profile,
                conversation_history=conversation_history
            )

            logger.info(f"Starting query routing for session: {session_id}")

            # åŸ·è¡Œå·¥ä½œæµç¨‹
            final_state = await self.workflow.ainvoke(initial_state)

            # æ›´æ–°ç‹€æ…‹ç®¡ç†å™¨
            self.state_manager.update_session_state(session_id, final_state)

            # è¿”å›çµæœ
            return {
                "session_id": session_id,
                "final_response": final_state["final_response"],
                "confidence_score": final_state["confidence_score"],
                "expert_responses": final_state["expert_responses"],
                "expert_sources": final_state["expert_sources"],
                "response_sources": final_state.get("response_sources", []),
                "status": final_state["status"].value,
                "llm_configured": is_llm_configured(),
                "agents_used": list(final_state["expert_responses"].keys())
            }

        except Exception as e:
            logger.error(f"Workflow execution failed for session {session_id}: {e}")
            return {
                "session_id": session_id,
                "final_response": f"å·¥ä½œæµç¨‹åŸ·è¡Œå¤±æ•—ï¼š{str(e)}",
                "confidence_score": 0.0,
                "expert_responses": {},
                "expert_sources": {},
                "status": "failed",
                "error": str(e)
            }

    async def _route_query(self, state: FinanceState) -> FinanceState:
        """è·¯ç”±æŸ¥è©¢åˆ°é©ç•¶çš„å°ˆå®¶"""
        try:
            query = state["user_query"]
            logger.info(f"Starting query routing for: {query[:50]}...")

            # ä½¿ç”¨ç®¡ç†ä»£ç†äººé€²è¡Œè·¯ç”±æ±ºç­–ï¼ˆæ·»åŠ è¶…æ™‚ä¿è­·ï¼‰
            routing_message = AgentMessage(
                agent_type=AgentType.MANAGER,
                message_type=MessageType.QUERY,
                content=query
            )

            logger.info("Calling manager agent for routing...")
            routing_response = await asyncio.wait_for(
                self.manager_agent.process_message(routing_message),
                timeout=10.0  # è·¯ç”±æ±ºç­–æœ€å¤š 10 ç§’
            )
            logger.info("Manager agent routing completed")

            # å®‰å…¨ç²å– metadata
            if routing_response.metadata and "required_experts" in routing_response.metadata:
                expert_names = routing_response.metadata["required_experts"]
            else:
                expert_names = ["financial_planner"]  # é»˜èªå€¼

            # è½‰æ›å­—ç¬¦ä¸²ç‚º AgentType æšèˆ‰
            required_experts = []
            for name in expert_names:
                if name == "financial_planner":
                    required_experts.append(AgentType.FINANCIAL_PLANNER)
                elif name == "financial_analyst":
                    required_experts.append(AgentType.FINANCIAL_ANALYST)
                elif name == "legal_expert":
                    required_experts.append(AgentType.LEGAL_EXPERT)
                else:
                    required_experts.append(AgentType.FINANCIAL_PLANNER)  # é»˜èª

            logger.info(f"Routing complete. Required experts: {[exp.value for exp in required_experts]}")

            # æ›´æ–°ç‹€æ…‹
            state["required_experts"] = required_experts
            state["routing_decision"] = routing_response.content

            return state

        except asyncio.TimeoutError:
            logger.error("Query routing timed out after 10s, using default expert")
            state["required_experts"] = [AgentType.FINANCIAL_PLANNER]  # é è¨­ä½¿ç”¨ç†è²¡è¦åŠƒå¸«
            state["routing_decision"] = "è·¯ç”±è¶…æ™‚ï¼Œä½¿ç”¨é è¨­ç†è²¡è¦åŠƒå°ˆå®¶"
            return state
        except Exception as e:
            logger.error(f"Query routing failed: {e}")
            import traceback
            traceback.print_exc()
            state["required_experts"] = [AgentType.FINANCIAL_PLANNER]  # é è¨­ä½¿ç”¨ç†è²¡è¦åŠƒå¸«
            return state

    async def _process_experts(self, state: FinanceState) -> FinanceState:
        """ä¸¦è¡Œè™•ç†å°ˆå®¶è«®è©¢

        Linus å¯¦ç”¨ä¸»ç¾©ï¼šå°‡å°è©±æ­·å²å‚³éçµ¦æ‰€æœ‰å°ˆå®¶
        """
        try:
            required_experts = state["required_experts"]
            query = state["user_query"]
            user_profile = state["user_profile"]
            conversation_history = state.get("conversation_history", [])

            logger.info(f"Processing experts for session: {state['session_id']}")
            logger.info(f"Required experts: {[e.value for e in required_experts]}")
            if conversation_history:
                logger.info(f"Using conversation history with {len(conversation_history)} messages")

            # æº–å‚™å°ˆå®¶ä»»å‹™ï¼ˆæ·»åŠ è¶…æ™‚ä¿è­·ï¼‰
            expert_tasks = []
            for expert_type in required_experts:
                if expert_type in self.experts:
                    logger.info(f"Preparing task for expert: {expert_type.value}")
                    message = AgentMessage(
                        agent_type=expert_type,
                        message_type=MessageType.QUERY,
                        content=query,
                        metadata={
                            "user_profile": user_profile,
                            "conversation_history": conversation_history  # å‚³éå°è©±æ­·å²
                        }
                    )
                    # æ·»åŠ è¶…æ™‚ä¿è­·ï¼šæ¯å€‹å°ˆå®¶æœ€å¤š 20 ç§’
                    task = asyncio.wait_for(
                        self._process_single_expert(expert_type, message),
                        timeout=20.0
                    )
                    expert_tasks.append((expert_type, task))
                else:
                    logger.warning(f"Expert type {expert_type.value} not found in experts dict")

            # çœŸæ­£ä¸¦è¡ŒåŸ·è¡Œæ‰€æœ‰å°ˆå®¶è«®è©¢ï¼ˆä½¿ç”¨ asyncio.gatherï¼‰
            logger.info(f"Starting parallel execution of {len(expert_tasks)} expert tasks...")
            expert_results = {}
            expert_sources = {}

            # åˆ†é›¢ expert_types å’Œ tasks
            expert_types = [et for et, _ in expert_tasks]
            tasks = [t for _, t in expert_tasks]

            # ä½¿ç”¨ gather ä¸¦è¡ŒåŸ·è¡Œï¼Œreturn_exceptions=True ç¢ºä¿å–®å€‹å¤±æ•—ä¸å½±éŸ¿å…¶ä»–
            results = await asyncio.gather(*tasks, return_exceptions=True)

            # è™•ç†çµæœ
            for expert_type, result in zip(expert_types, results):
                try:
                    if isinstance(result, Exception):
                        # è™•ç†ç•°å¸¸ï¼ˆåŒ…æ‹¬è¶…æ™‚ï¼‰
                        if isinstance(result, asyncio.TimeoutError):
                            logger.error(f"Expert {expert_type.value} timed out after 20s")
                            error_msg = "å°ˆå®¶è™•ç†è¶…æ™‚ï¼Œè«‹ç¨å¾Œå†è©¦"
                        else:
                            logger.error(f"Expert {expert_type.value} failed: {result}")
                            error_msg = f"å°ˆå®¶è«®è©¢å¤±æ•—ï¼š{str(result)}"

                        expert_results[expert_type.value] = {
                            "content": error_msg,
                            "confidence": 0.0,
                            "metadata": {"error": str(result)}
                        }
                        expert_sources[expert_type.value] = []
                    else:
                        # æˆåŠŸéŸ¿æ‡‰
                        response = result
                        expert_results[expert_type.value] = {
                            "content": response.content,
                            "confidence": response.confidence,
                            "metadata": response.metadata
                        }
                        expert_sources[expert_type.value] = response.sources
                        logger.info(f"Expert {expert_type.value} responded successfully")

                except Exception as e:
                    logger.error(f"Error processing result from {expert_type.value}: {e}")
                    expert_results[expert_type.value] = {
                        "content": f"çµæœè™•ç†å¤±æ•—ï¼š{str(e)}",
                        "confidence": 0.0,
                        "metadata": {"error": str(e)}
                    }
                    expert_sources[expert_type.value] = []

            logger.info(f"Expert processing complete. Got {len(expert_results)} results")

            # æ›´æ–°ç‹€æ…‹
            state["expert_responses"] = expert_results
            state["expert_sources"] = expert_sources

            return state

        except Exception as e:
            logger.error(f"Expert processing failed: {e}")
            import traceback
            traceback.print_exc()
            state["expert_responses"] = {}
            state["expert_sources"] = {}
            return state

    async def _process_single_expert(self, expert_type: AgentType, message: AgentMessage):
        """è™•ç†å–®ä¸€å°ˆå®¶è«®è©¢"""
        expert = self.experts[expert_type]
        return await expert.process_message(message)

    async def _integrate_responses(self, state: FinanceState) -> FinanceState:
        """æ•´åˆå°ˆå®¶å›æ‡‰"""
        try:
            logger.info(f"Integrating responses for session: {state['session_id']}")

            expert_responses = state["expert_responses"]

            if not expert_responses:
                state["final_response"] = "ç„¡æ³•ç²å¾—å°ˆå®¶å›æ‡‰ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
                state["confidence_score"] = 0.0
                state["status"] = WorkflowStatus.FAILED
                return state

            # å¦‚æœåªæœ‰ä¸€å€‹å°ˆå®¶å›æ‡‰ï¼Œç›´æ¥ä½¿ç”¨
            if len(expert_responses) == 1:
                expert_type, response_data = next(iter(expert_responses.items()))
                state["final_response"] = response_data["content"]
                state["confidence_score"] = response_data["confidence"]
            else:
                # å¤šå°ˆå®¶å›æ‡‰æ•´åˆ
                integrated_response = self._merge_expert_responses(expert_responses)
                state["final_response"] = integrated_response["content"]
                state["confidence_score"] = integrated_response["confidence"]

            # æ”¶é›†æ‰€æœ‰ä¾†æº
            all_sources = []
            for sources in state["expert_sources"].values():
                all_sources.extend(sources)
            state["response_sources"] = list(set(all_sources))

            # æ›´æ–°ç‹€æ…‹
            state["status"] = WorkflowStatus.COMPLETED
            state["processing_end_time"] = datetime.now()

            logger.info(f"Response integration complete. Confidence: {state['confidence_score']}")

            return state

        except Exception as e:
            logger.error(f"Response integration failed: {e}")
            state["final_response"] = f"å›æ‡‰æ•´åˆå¤±æ•—ï¼š{str(e)}"
            state["confidence_score"] = 0.0
            state["status"] = WorkflowStatus.FAILED
            return state

    def _merge_expert_responses(self, expert_responses: Dict) -> Dict:
        """åˆä½µå¤šå€‹å°ˆå®¶å›æ‡‰"""
        try:
            # ç°¡å–®çš„å›æ‡‰åˆä½µç­–ç•¥
            contents = []
            confidences = []

            for expert_type, response_data in expert_responses.items():
                if response_data["content"]:
                    contents.append(f"**{expert_type}å»ºè­°**ï¼š\n{response_data['content']}")
                    confidences.append(response_data["confidence"])

            if not contents:
                return {
                    "content": "ç„¡æ³•ç”Ÿæˆå°ˆå®¶å»ºè­°ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚",
                    "confidence": 0.0
                }

            # åˆä½µå…§å®¹
            merged_content = "\n\n".join(contents)

            # è¨ˆç®—å¹³å‡ä¿¡å¿ƒåº¦
            avg_confidence = sum(confidences) / len(confidences) if confidences else 0.0

            return {
                "content": merged_content,
                "confidence": avg_confidence
            }

        except Exception as e:
            logger.error(f"Response merging failed: {e}")
            return {
                "content": "å›æ‡‰åˆä½µå¤±æ•—",
                "confidence": 0.0
            }

    def get_workflow_status(self, session_id: str) -> Dict:
        """å–å¾—å·¥ä½œæµç¨‹ç‹€æ…‹"""
        try:
            state = self.state_manager.get_session_state(session_id)
            if not state:
                return {"error": "Session not found"}

            return {
                "session_id": session_id,
                "status": state["status"].value if state.get("status") else "unknown",
                "expert_count": len(state.get("expert_responses", {})),
                "confidence_score": state.get("confidence_score", 0.0),
                "llm_configured": is_llm_configured()
            }

        except Exception as e:
            logger.error(f"Error getting workflow status: {e}")
            return {"error": str(e)}

    def get_system_info(self) -> Dict[str, Any]:
        """å–å¾—ç³»çµ±è³‡è¨Š"""
        return {
            "workflow_type": "LLM-Enhanced Finance Workflow",
            "llm_configured": is_llm_configured(),
            "agents": {
                name: agent.get_llm_status()
                for name, agent in self.experts.items()
            },
            "rag_system": bool(self.knowledge_retriever),
            "personal_db": bool(self.personal_db),
            "active_sessions": len(self.state_manager.session_id)
        }

    async def run_stream(
        self,
        user_query: str,
        user_profile: Dict = None,
        session_id: str = None,
        conversation_history: List[Dict[str, str]] = None
    ):
        """åŸ·è¡Œç†è²¡è«®è©¢å·¥ä½œæµç¨‹ï¼ˆæµå¼æ¨¡å¼ï¼‰

        é€™å€‹æ–¹æ³•ç¹é LangGraphï¼Œç›´æ¥é€²è¡Œæµå¼è™•ç†ï¼Œè®“ç”¨æˆ¶æ›´å¿«çœ‹åˆ°ç¬¬ä¸€å€‹å›æ‡‰

        Args:
            user_query: ä½¿ç”¨è€…æŸ¥è©¢
            user_profile: ä½¿ç”¨è€…è³‡æ–™
            session_id: æœƒè©± ID
            conversation_history: å°è©±æ­·å²

        Yields:
            str: é€å¡Šç”Ÿæˆçš„å›æ‡‰å…§å®¹
        """
        session_id = session_id or str(uuid.uuid4())

        try:
            # æ­¥é©Ÿ 1: è·¯ç”±æ±ºç­–ï¼ˆå¿«é€Ÿï¼Œ1-2ç§’ï¼‰
            logger.info(f"[Stream] Starting routing for session: {session_id}")
            routing_message = AgentMessage(
                agent_type=AgentType.MANAGER,
                message_type=MessageType.QUERY,
                content=user_query
            )

            routing_response = await asyncio.wait_for(
                self.manager_agent.process_message(routing_message),
                timeout=10.0
            )

            # ç²å–éœ€è¦çš„å°ˆå®¶
            if routing_response.metadata and "required_experts" in routing_response.metadata:
                expert_names = routing_response.metadata["required_experts"]
            else:
                expert_names = ["financial_planner"]

            # è½‰æ›ç‚º AgentType
            required_experts = []
            for name in expert_names:
                if name == "financial_planner":
                    required_experts.append(AgentType.FINANCIAL_PLANNER)
                elif name == "financial_analyst":
                    required_experts.append(AgentType.FINANCIAL_ANALYST)
                elif name == "legal_expert":
                    required_experts.append(AgentType.LEGAL_EXPERT)

            logger.info(f"[Stream] Experts required: {[e.value for e in required_experts]}")

            # æ­¥é©Ÿ 2: æµå¼è™•ç†å°ˆå®¶å›æ‡‰
            # ç­–ç•¥ï¼šä¾åºè™•ç†æ¯å€‹å°ˆå®¶ï¼Œä¸¦å³æ™‚æµå¼è¼¸å‡º
            all_rag_docs = []  # æ”¶é›†æ‰€æœ‰å°ˆå®¶çš„ RAG æª¢ç´¢çµæœ

            for expert_type in required_experts:
                if expert_type not in self.experts:
                    continue

                expert = self.experts[expert_type]
                logger.info(f"[Stream] Processing expert: {expert_type.value}")

                # æº–å‚™è¨Šæ¯
                message = AgentMessage(
                    agent_type=expert_type,
                    message_type=MessageType.QUERY,
                    content=user_query,
                    metadata={
                        "user_profile": user_profile or {},
                        "conversation_history": conversation_history or []
                    }
                )

                # æª¢æŸ¥ expert æ˜¯å¦æœ‰æµå¼æ–¹æ³•
                if hasattr(expert, 'process_message_stream'):
                    # ä½¿ç”¨æµå¼è™•ç†
                    logger.info(f"[Stream] Using stream mode for {expert_type.value}")
                    async for chunk in expert.process_message_stream(message):
                        yield chunk

                    # æ”¶é›† RAG æª¢ç´¢çµæœ
                    if hasattr(expert, 'last_retrieved_docs') and expert.last_retrieved_docs:
                        all_rag_docs.extend(expert.last_retrieved_docs)
                else:
                    # é™ç´šåˆ°æ™®é€šæ¨¡å¼ï¼ˆç„¡è¶…æ™‚é™åˆ¶ï¼Œè®“ LLM è‡ªç„¶å®Œæˆï¼‰
                    logger.info(f"[Stream] Falling back to normal mode for {expert_type.value}")
                    response = await expert.process_message(message)

                    # æ¨¡æ“¬æµå¼è¼¸å‡º
                    content = response.content
                    chunk_size = 10
                    for i in range(0, len(content), chunk_size):
                        yield content[i:i+chunk_size]
                        await asyncio.sleep(0.01)  # 10ms å»¶é²

                # å¦‚æœæœ‰å¤šå€‹å°ˆå®¶ï¼Œåœ¨å°ˆå®¶ä¹‹é–“æ·»åŠ åˆ†éš”
                if len(required_experts) > 1 and expert_type != required_experts[-1]:
                    yield "\n\n---\n\n"

            # æ­¥é©Ÿ 3: åœ¨å›æ‡‰æœ«å°¾é™„åŠ  RAG ä¾†æºæ–‡ä»¶
            if all_rag_docs:
                yield "\n\n---\n\n### ğŸ“š åƒè€ƒè³‡æ–™ä¾†æº\n\n"
                for idx, doc in enumerate(all_rag_docs[:5], 1):  # æœ€å¤šé¡¯ç¤º 5 å€‹ä¾†æº
                    # RAG æ–‡ä»¶æ˜¯ RetrievalResult dataclass ç‰©ä»¶
                    # å±¬æ€§: content, metadata, similarity_score, source, expert_domain, confidence
                    metadata = doc.metadata if hasattr(doc, 'metadata') else {}

                    title = metadata.get('title', 'æœªçŸ¥æ¨™é¡Œ')
                    category = metadata.get('category', 'æœªåˆ†é¡')
                    url = metadata.get('url', '')

                    # ä½¿ç”¨ scrape_time ä½œç‚ºæ™‚é–“ï¼ˆåŸå§‹è³‡æ–™æ²’æœ‰ publish_timeï¼‰
                    scrape_time = metadata.get('scrape_time', '')
                    if scrape_time:
                        # æ ¼å¼åŒ–æ™‚é–“ï¼šå¾ "2025-09-27T13:21:14.501841" æå– "2025-09-27"
                        time_display = scrape_time.split('T')[0] if 'T' in scrape_time else scrape_time
                    else:
                        time_display = '--'

                    # source æ˜¯ dataclass çš„ç›´æ¥å±¬æ€§
                    source = doc.source if hasattr(doc, 'source') else metadata.get('source', 'æœªçŸ¥ä¾†æº')

                    yield f"**{idx}. {title}**\n"
                    yield f"   - ğŸ“‚ åˆ†é¡ï¼š{category}\n"
                    yield f"   - ğŸ“… è³‡æ–™æ™‚é–“ï¼š{time_display}\n"
                    yield f"   - ğŸŒ ä¾†æºï¼š{source}\n"
                    if url:
                        yield f"   - ğŸ”— [æŸ¥çœ‹åŸæ–‡]({url})\n"
                    yield "\n"

            logger.info(f"[Stream] Completed for session: {session_id}")

        except asyncio.TimeoutError:
            logger.error("[Stream] Processing timed out")
            yield "æŠ±æ­‰ï¼Œè™•ç†è¶…æ™‚ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
        except Exception as e:
            logger.error(f"[Stream] Error: {e}")
            import traceback
            traceback.print_exc()
            yield f"æŠ±æ­‰ï¼Œè™•ç†æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}"