"""
FinancialAnalystAgent with Real LLM Integration - é‡‘èåˆ†æå°ˆå®¶ (çœŸå¯¦ LLM ç‰ˆæœ¬)

å¯¦ä½œ Linus å“²å­¸ï¼š
1. ç°¡æ½”åŸ·å¿µï¼šå°ˆæ³¨å¸‚å ´åˆ†æå’ŒæŠ•è³‡æ±ºç­–æ”¯æ´
2. å¥½å“å‘³ï¼šåŸºæ–¼æ•¸æ“šçš„å®¢è§€åˆ†æçµè«–
3. å¯¦ç”¨ä¸»ç¾©ï¼šæä¾›å¯æ“ä½œçš„æŠ•è³‡å»ºè­°
4. Never break userspaceï¼šä¸€è‡´çš„åˆ†æå ±å‘Šæ ¼å¼
"""

import logging
import re
from datetime import datetime
from typing import Any, Dict, List, Optional

from .base_agent import AgentMessage, AgentType, BaseAgent, MessageType
from .llm_base_agent import LLMBaseAgent

try:
    from ..llm import generate_llm_response, is_llm_configured
except ImportError:
    try:
        from llm import generate_llm_response, is_llm_configured
    except ImportError:
        async def generate_llm_response(prompt, **kwargs):
            return type('MockResponse', (), {'content': 'æ¨¡æ“¬å›æ‡‰', 'model': 'mock'})()
        def is_llm_configured():
            return False


class FinancialAnalystAgentLLM(LLMBaseAgent):
    """é‡‘èåˆ†æå°ˆå®¶ä»£ç†äºº (ä½¿ç”¨çœŸå¯¦ LLM)

    ç‰¹è‰²ï¼š
    - ä½¿ç”¨çœŸå¯¦çš„ LLM (OpenAI/Anthropic) ç”Ÿæˆåˆ†æ
    - çµåˆ RAG æª¢ç´¢çš„å¸‚å ´è³‡è¨Š
    - å°ˆæ¥­çš„é‡‘èåˆ†ææç¤ºè©
    - çµæ§‹åŒ–çš„åˆ†æå ±å‘Šè¼¸å‡º
    """

    def __init__(self, name: str = "é‡‘èåˆ†æå°ˆå®¶", knowledge_retriever=None):
        super().__init__(
            agent_type=AgentType.FINANCIAL_ANALYST,
            name=name,
            use_rag=True,
            knowledge_retriever=knowledge_retriever
        )

        self.logger = logging.getLogger(__name__)

        # æª¢æŸ¥ LLM é…ç½®
        if not is_llm_configured():
            self.logger.warning("No LLM configured, falling back to template responses")

        # åˆ†æå°ˆæ¥­é ˜åŸŸ
        self.analysis_domains = {
            "technical_analysis": "æŠ€è¡“åˆ†æ",
            "fundamental_analysis": "åŸºæœ¬é¢åˆ†æ",
            "market_analysis": "å¸‚å ´åˆ†æ",
            "risk_assessment": "é¢¨éšªè©•ä¼°",
            "sector_analysis": "ç”¢æ¥­åˆ†æ"
        }

    async def _build_prompt(self,
                          query: str,
                          knowledge_results: List[Dict],
                          personal_context: Dict[str, Any]) -> str:
        """æ§‹å»ºé‡‘èåˆ†æå°ˆæ¥­æç¤ºè©"""

        # åˆ†ææŸ¥è©¢é¡å‹
        analysis_domain = self._classify_analysis_domain(query)
        domain_name = self.analysis_domains.get(analysis_domain, "å¸‚å ´åˆ†æ")

        # æ ¼å¼åŒ–çŸ¥è­˜ä¸Šä¸‹æ–‡
        knowledge_context = self._format_knowledge_context(knowledge_results)

        return f"""ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„é‡‘èåˆ†æå¸«ï¼Œè«‹æ ¹æ“šä»¥ä¸‹è³‡è¨Šæä¾›å°ˆæ¥­çš„{domain_name}ï¼š

ç”¨æˆ¶æŸ¥è©¢ï¼š{query}

ç›¸é—œå¸‚å ´è³‡è¨Šï¼š
{knowledge_context}

è«‹æä¾›çµæ§‹åŒ–çš„åˆ†æå ±å‘Šï¼ŒåŒ…å«ï¼š

ğŸ“ˆ **{domain_name}å ±å‘Š**

ğŸ“Š **ç•¶å‰å¸‚å ´ç‹€æ³**
- åŸºæ–¼æä¾›çš„å¸‚å ´è³‡è¨Šé€²è¡Œå®¢è§€åˆ†æ
- çµåˆæ­·å²è¶¨å‹¢å’Œç•¶å‰ç‹€æ³

ğŸ’¡ **é—œéµç™¼ç¾**
1. **æ ¸å¿ƒè§€é»**ï¼šåŸºæ–¼æ•¸æ“šçš„å®¢è§€åˆ¤æ–·
2. **é¢¨éšªå› å­**ï¼šè­˜åˆ¥ä¸»è¦é¢¨éšªå’Œä¸ç¢ºå®šæ€§
3. **æ©Ÿæœƒåˆ†æ**ï¼šæ½›åœ¨çš„æŠ•è³‡æ©Ÿæœƒ

ğŸ“‹ **å°ˆæ¥­å»ºè­°**
- å…·é«”å¯åŸ·è¡Œçš„æŠ•è³‡ç­–ç•¥
- é©åˆçš„æŠ•è³‡æ™‚æ©Ÿå’Œæ–¹æ³•
- é¢¨éšªæ§åˆ¶æªæ–½

âš ï¸ **é¢¨éšªæé†’**
- æŠ•è³‡é¢¨éšªè­¦èª
- å¸‚å ´ä¸ç¢ºå®šæ€§æé†’

åˆ†æè¦æ±‚ï¼š
1. ä¿æŒå®¢è§€å°ˆæ¥­ï¼ŒåŸºæ–¼äº‹å¯¦å’Œæ•¸æ“š
2. é¿å…éåº¦æ¨‚è§€æˆ–æ‚²è§€çš„é æ¸¬
3. æä¾›å…·é«”å¯è¡Œçš„å»ºè­°
4. ä½¿ç”¨ç¹é«”ä¸­æ–‡å›æ‡‰
5. æ ¼å¼è¦æ¸…æ™°æ˜“è®€ï¼Œä½¿ç”¨é©ç•¶çš„ Markdown æ¨™è¨˜
"""

    async def _generate_fallback_response(self, prompt: str) -> str:
        """LLM ä¸å¯ç”¨æ™‚çš„é‡‘èåˆ†æé™ç´šå›æ‡‰"""
        return """ğŸ“ˆ **å¸‚å ´åˆ†æå ±å‘Š**

ğŸ“Š **ç•¶å‰å¸‚å ´ç‹€æ³**
- åŸºæ–¼æœ€æ–°å¸‚å ´è³‡è¨Šé€²è¡Œåˆ†æ
- è€ƒé‡ç¸½é«”ç¶“æ¿Ÿç’°å¢ƒå½±éŸ¿
- çµåˆæ­·å²æ•¸æ“šæ¯”è¼ƒ

ğŸ’¡ **é—œéµç™¼ç¾**
1. **è¶¨å‹¢åˆ¤æ–·**ï¼šæ ¹æ“šæŠ€è¡“æŒ‡æ¨™å’ŒåŸºæœ¬é¢æ•¸æ“šåˆ†æ
2. **é¢¨éšªè©•ä¼°**ï¼šè­˜åˆ¥ä¸»è¦é¢¨éšªå› å­å’Œä¸ç¢ºå®šæ€§
3. **æ©Ÿæœƒé»**ï¼šæ½›åœ¨æŠ•è³‡æ©Ÿæœƒå’Œé€²å ´æ™‚æ©Ÿ

ğŸ“‹ **æŠ•è³‡å»ºè­°**
- å»ºè­°æ¡ç”¨åˆ†æ•£æŠ•è³‡ç­–ç•¥
- å®šæœŸæª¢è¦–æŠ•è³‡çµ„åˆè¡¨ç¾
- æ ¹æ“šé¢¨éšªæ‰¿å—åº¦èª¿æ•´é…ç½®

âš ï¸ **é¢¨éšªæé†’**
- æŠ•è³‡æœ‰é¢¨éšªï¼Œéå¾€ç¸¾æ•ˆä¸ä»£è¡¨æœªä¾†è¡¨ç¾
- å»ºè­°åˆ†æ•£æŠ•è³‡ï¼Œæ§åˆ¶å–®ä¸€æ¨™çš„æŠ•è³‡æ¯”é‡
- å®šæœŸæª¢è¦–æŠ•è³‡çµ„åˆï¼Œé©æ™‚èª¿æ•´ç­–ç•¥

*æ³¨æ„ï¼šæ­¤ç‚ºé è¨­åˆ†ææ¨¡æ¿ï¼Œå»ºè­°é…ç½® LLM API ä»¥ç²å¾—æ›´è©³ç´°çš„å€‹äººåŒ–åˆ†æã€‚*
"""

    def _get_system_prompt(self) -> str:
        """é‡‘èåˆ†æå°ˆå®¶çš„ç³»çµ±æç¤ºè©"""
        return """ä½ æ˜¯å°ˆæ¥­çš„é‡‘èåˆ†æå¸«ï¼Œå°ˆç²¾æ–¼è‚¡ç¥¨ã€å‚µåˆ¸ã€åŸºé‡‘ç­‰é‡‘èå•†å“çš„æ·±åº¦åˆ†æç ”ç©¶ã€‚

# å°ˆæ¥­é ˜åŸŸ
- æŠ€è¡“åˆ†æï¼šåƒ¹æ ¼èµ°å‹¢ã€æŠ€è¡“æŒ‡æ¨™ã€äº¤æ˜“è¨Šè™Ÿåˆ†æ
- åŸºæœ¬é¢åˆ†æï¼šè²¡å‹™å ±è¡¨ã€å…¬å¸ä¼°å€¼ã€ç”¢æ¥­ç ”ç©¶
- å¸‚å ´åˆ†æï¼šç¸½é«”ç¶“æ¿Ÿã€æ”¿ç­–å½±éŸ¿ã€å¸‚å ´è¶¨å‹¢
- æŠ•è³‡ç­–ç•¥ï¼šé¸è‚¡é‚è¼¯ã€é€²å‡ºå ´æ™‚æ©Ÿã€é¢¨éšªæ§åˆ¶

# åˆ†ææ¡†æ¶
1. **æ•¸æ“šé©…å‹•**: åŸºæ–¼å®¢è§€æ•¸æ“šå’Œæ­·å²è³‡æ–™é€²è¡Œåˆ†æ
2. **å¤šè§’åº¦åˆ†æ**: çµåˆæŠ€è¡“é¢ã€åŸºæœ¬é¢ã€ç¸½é«”é¢è§€é»
3. **é¢¨éšªè©•ä¼°**: è­˜åˆ¥ä¸¦é‡åŒ–æŠ•è³‡é¢¨éšª
4. **å¯¦å‹™å°å‘**: æä¾›å¯åŸ·è¡Œçš„æŠ•è³‡å»ºè­°

# å›æ‡‰æ ¼å¼
ğŸ“ˆ **å¸‚å ´/å€‹è‚¡åˆ†æ**
- ç•¶å‰ç‹€æ³è©•ä¼°
- é—œéµæŠ€è¡“/åŸºæœ¬é¢æŒ‡æ¨™
- è¶¨å‹¢åˆ¤æ–·èˆ‡é æ¸¬

ğŸ“Š **æ•¸æ“šè§£è®€**
- é‡è¦è²¡å‹™/æŠ€è¡“æŒ‡æ¨™èªªæ˜
- åŒæ¥­æˆ–æ­·å²æ¯”è¼ƒ
- ç•°å¸¸ç‹€æ³åˆ†æ

ğŸ’¡ **æŠ•è³‡å»ºè­°**
- é€²å‡ºå ´æ™‚æ©Ÿå»ºè­°
- ç›®æ¨™åƒ¹ä½è¨­å®š
- åœæåœåˆ©ç­–ç•¥

âš ï¸ **é¢¨éšªè­¦ç¤º**
- ä¸»è¦é¢¨éšªå› å­è­˜åˆ¥
- å¸‚å ´ä¸ç¢ºå®šæ€§æé†’
- å»ºè­°é¢¨éšªæ§åˆ¶æªæ–½

ğŸ” **å¾ŒçºŒè§€å¯Ÿé‡é»**
- éœ€é—œæ³¨çš„é—œéµæŒ‡æ¨™
- é‡è¦æ™‚é–“ç¯€é»æé†’

æ³¨æ„ï¼šåˆ†æåŸºæ–¼ç¾æœ‰è³‡æ–™ï¼Œå¸‚å ´å…·ä¸ç¢ºå®šæ€§ï¼ŒæŠ•è³‡å‰è«‹å¯©æ…è©•ä¼°ã€‚

æˆ‘æœƒçµåˆæª¢ç´¢åˆ°çš„æœ€æ–°å¸‚å ´è³‡è¨Šå’Œæ­·å²æ•¸æ“šä¾†æä¾›å°ˆæ¥­åˆ†æã€‚"""

    async def can_handle(self, query: str) -> float:
        """è©•ä¼°æ˜¯å¦èƒ½è™•ç†é‡‘èåˆ†æç›¸é—œæŸ¥è©¢"""
        query_lower = query.lower()

        # è¨ˆç®—é‡‘èåˆ†æé—œéµå­—åŒ¹é…åº¦
        analysis_keywords = [
            "æŠ€è¡“åˆ†æ", "åŸºæœ¬é¢åˆ†æ", "å¸‚å ´åˆ†æ", "è‚¡ç¥¨åˆ†æ", "æŠ•è³‡åˆ†æ",
            "è²¡å ±åˆ†æ", "ç”¢æ¥­åˆ†æ", "è¶¨å‹¢åˆ†æ", "Kç·š", "ç§»å‹•å¹³å‡", "RSI", "MACD",
            "æœ¬ç›Šæ¯”", "ROE", "ç‡Ÿæ”¶", "ç²åˆ©", "è‚¡åƒ¹æ·¨å€¼æ¯”", "æŠ€è¡“æŒ‡æ¨™",
            "stock", "market", "analysis", "economic", "trend", "data",
            "åˆ†æ", "è‚¡ç¥¨", "æŠ•è³‡", "å¸‚å ´", "æŠ€è¡“", "åŸºæœ¬é¢", "è²¡å ±",
            "æœ¬ç›Šæ¯”", "è¶¨å‹¢", "æŒ‡æ¨™", "åƒ¹æ ¼", "è©•ä¼°"
        ]

        keyword_count = sum(1 for keyword in analysis_keywords if keyword in query_lower)
        keyword_score = min(keyword_count / 6, 1.0) * 0.6

        # æ•¸æ“š/æŒ‡æ¨™ç›¸é—œè©å½™åŠ åˆ†
        data_terms = ["æ•¸æ“š", "æŒ‡æ¨™", "æ¯”ç‡", "å ±é…¬ç‡", "ç¸¾æ•ˆ", "èµ°å‹¢", "åƒ¹æ ¼"]
        data_count = sum(1 for term in data_terms if term in query)
        data_score = min(data_count / 3, 1.0) * 0.3

        # å…·é«”æ€§è©•åˆ†ï¼ˆæ˜¯å¦æåŠå…·é«”è‚¡ç¥¨ã€æ•¸æ“šç­‰ï¼‰
        specificity_indicators = ["è‚¡ç¥¨ä»£è™Ÿ", "å…¬å¸åç¨±", "å…·é«”æ•¸å­—", "æ™‚é–“ç¯„åœ"]
        has_specific = any(
            indicator in query for indicator in ["2330", "å°ç©é›»", "%", "å…ƒ", "å¹´", "æœˆ"]
        )
        specificity_score = 0.1 if has_specific else 0

        final_score = keyword_score + data_score + specificity_score

        self.logger.debug(
            f"é‡‘èåˆ†æå°ˆå®¶èƒ½åŠ›è©•åˆ†: {final_score:.2f} "
            f"(é—œéµå­—: {keyword_score:.2f}, æ•¸æ“šå°å‘: {data_score:.2f}, å…·é«”æ€§: {specificity_score:.2f})"
        )

        return min(final_score, 1.0)

    def _classify_analysis_domain(self, query: str) -> str:
        """åˆ†é¡åˆ†æé ˜åŸŸ"""
        query_lower = query.lower()

        # æŠ€è¡“åˆ†æé—œéµå­—
        if any(keyword in query_lower for keyword in
               ["æŠ€è¡“åˆ†æ", "kç·š", "ç§»å‹•å¹³å‡", "macd", "rsi", "æ”¯æ’", "å£“åŠ›", "è¶¨å‹¢"]):
            return "technical_analysis"

        # åŸºæœ¬é¢åˆ†æé—œéµå­—
        elif any(keyword in query_lower for keyword in
                 ["åŸºæœ¬é¢", "è²¡å ±", "æœ¬ç›Šæ¯”", "roe", "ç‡Ÿæ”¶", "ç²åˆ©", "è²¡å‹™"]):
            return "fundamental_analysis"

        # é¢¨éšªè©•ä¼°é—œéµå­—
        elif any(keyword in query_lower for keyword in
                 ["é¢¨éšª", "æ³¢å‹•", "é¢¨éšªè©•ä¼°", "æŠ•è³‡é¢¨éšª"]):
            return "risk_assessment"

        # ç”¢æ¥­åˆ†æé—œéµå­—
        elif any(keyword in query_lower for keyword in
                 ["ç”¢æ¥­", "é¡è‚¡", "æ¿å¡Š", "sector", "è¡Œæ¥­"]):
            return "sector_analysis"

        # é è¨­ç‚ºå¸‚å ´åˆ†æ
        else:
            return "market_analysis"


    def get_analysis_capabilities(self) -> Dict[str, Any]:
        """å–å¾—åˆ†æèƒ½åŠ›æè¿°"""
        return {
            "supported_domains": list(self.analysis_domains.values()),
            "llm_configured": is_llm_configured(),
            "features": [
                "æŠ€è¡“åˆ†æ",
                "åŸºæœ¬é¢åˆ†æ",
                "å¸‚å ´åˆ†æ",
                "é¢¨éšªè©•ä¼°",
                "ç”¢æ¥­åˆ†æ"
            ],
            "data_sources": "RAG æª¢ç´¢ + å³æ™‚å¸‚å ´è³‡è¨Š"
        }