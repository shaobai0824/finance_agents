"""
FinancialAnalystAgent with Real LLM Integration - é‡‘èåˆ†æå°ˆå®¶ (çœŸå¯¦ LLM ç‰ˆæœ¬)

å¯¦ä½œ Linus å“²å­¸ï¼š
1. ç°¡æ½”åŸ·å¿µï¼šå°ˆæ³¨å¸‚å ´åˆ†æå’ŒæŠ•è³‡æ±ºç­–æ”¯æ´
2. å¥½å“å‘³ï¼šåŸºæ–¼æ•¸æ“šçš„å®¢è§€åˆ†æçµè«–
3. å¯¦ç”¨ä¸»ç¾©ï¼šæä¾›å¯æ“ä½œçš„æŠ•è³‡å»ºè­°
4. Never break userspaceï¼šä¸€è‡´çš„åˆ†æå ±å‘Šæ ¼å¼
"""

from typing import Dict, Any, List, Optional
from datetime import datetime
import re
import logging

from .base_agent import BaseAgent, AgentMessage, AgentType, MessageType
from .llm_base_agent import LLMBaseAgent
from ..llm import generate_llm_response, is_llm_configured


class FinancialAnalystAgentLLM(LLMBaseAgent):
    """é‡‘èåˆ†æå°ˆå®¶ä»£ç†äºº (ä½¿ç”¨çœŸå¯¦ LLM)

    ç‰¹è‰²ï¼š
    - ä½¿ç”¨çœŸå¯¦çš„ LLM (OpenAI/Anthropic) ç”Ÿæˆåˆ†æ
    - çµåˆ RAG æª¢ç´¢çš„å¸‚å ´è³‡è¨Š
    - å°ˆæ¥­çš„é‡‘èåˆ†ææç¤ºè©
    - çµæ§‹åŒ–çš„åˆ†æå ±å‘Šè¼¸å‡º
    """

    def __init__(self, name: str = "é‡‘èåˆ†æå°ˆå®¶", knowledge_retriever=None):
        super().__init__(
            agent_type=AgentType.FINANCIAL_ANALYST,
            name=name,
            use_rag=True,
            knowledge_retriever=knowledge_retriever
        )

        self.logger = logging.getLogger(__name__)

        # æª¢æŸ¥ LLM é…ç½®
        if not is_llm_configured():
            self.logger.warning("No LLM configured, falling back to template responses")

        # åˆ†æå°ˆæ¥­é ˜åŸŸ
        self.analysis_domains = {
            "technical_analysis": "æŠ€è¡“åˆ†æ",
            "fundamental_analysis": "åŸºæœ¬é¢åˆ†æ",
            "market_analysis": "å¸‚å ´åˆ†æ",
            "risk_assessment": "é¢¨éšªè©•ä¼°",
            "sector_analysis": "ç”¢æ¥­åˆ†æ"
        }

    async def process_message(self, message: AgentMessage) -> AgentMessage:
        """è™•ç†è¨Šæ¯ä¸¦ç”Ÿæˆå°ˆæ¥­é‡‘èåˆ†æ"""
        try:
            query = message.content.strip()

            # 1. RAG æª¢ç´¢ç›¸é—œå¸‚å ´è³‡è¨Š
            knowledge_results = await self._retrieve_knowledge(query, max_results=8)
            knowledge_context = self._format_knowledge_context(knowledge_results)

            # 2. åˆ†ææŸ¥è©¢é¡å‹
            analysis_domain = self._classify_analysis_domain(query)

            # 3. ä½¿ç”¨ LLM ç”Ÿæˆå°ˆæ¥­åˆ†æ
            analysis_report = await self._generate_llm_analysis(
                query, analysis_domain, knowledge_context
            )

            # 4. è¨ˆç®—ä¿¡å¿ƒåº¦
            confidence = self._calculate_confidence(query, knowledge_results)

            # 5. å»ºç«‹å›æ‡‰
            response = self.create_response(
                content=analysis_report,
                metadata={
                    "analysis_domain": analysis_domain,
                    "knowledge_used": len(knowledge_results),
                    "analysis_time": datetime.now().isoformat(),
                    "agent_type": "financial_analyst_llm",
                    "llm_configured": is_llm_configured()
                },
                sources=self._extract_sources(knowledge_results),
                confidence=confidence
            )

            self.log_interaction(message, response)
            return response

        except Exception as e:
            self.logger.error(f"Error processing message: {e}")
            return self.create_error_response(
                f"åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}",
                metadata={"error_type": "processing_error"}
            )

    def _classify_analysis_domain(self, query: str) -> str:
        """åˆ†é¡åˆ†æé ˜åŸŸ"""
        query_lower = query.lower()

        # æŠ€è¡“åˆ†æé—œéµå­—
        if any(keyword in query_lower for keyword in
               ["æŠ€è¡“åˆ†æ", "kç·š", "ç§»å‹•å¹³å‡", "macd", "rsi", "æ”¯æ’", "å£“åŠ›", "è¶¨å‹¢"]):
            return "technical_analysis"

        # åŸºæœ¬é¢åˆ†æé—œéµå­—
        elif any(keyword in query_lower for keyword in
                 ["åŸºæœ¬é¢", "è²¡å ±", "æœ¬ç›Šæ¯”", "roe", "ç‡Ÿæ”¶", "ç²åˆ©", "è²¡å‹™"]):
            return "fundamental_analysis"

        # é¢¨éšªè©•ä¼°é—œéµå­—
        elif any(keyword in query_lower for keyword in
                 ["é¢¨éšª", "æ³¢å‹•", "é¢¨éšªè©•ä¼°", "æŠ•è³‡é¢¨éšª"]):
            return "risk_assessment"

        # ç”¢æ¥­åˆ†æé—œéµå­—
        elif any(keyword in query_lower for keyword in
                 ["ç”¢æ¥­", "é¡è‚¡", "æ¿å¡Š", "sector", "è¡Œæ¥­"]):
            return "sector_analysis"

        # é è¨­ç‚ºå¸‚å ´åˆ†æ
        else:
            return "market_analysis"

    async def _generate_llm_analysis(self,
                                   query: str,
                                   analysis_domain: str,
                                   knowledge_context: str) -> str:
        """ä½¿ç”¨ LLM ç”Ÿæˆå°ˆæ¥­é‡‘èåˆ†æ"""

        # å¦‚æœæ²’æœ‰é…ç½® LLMï¼Œä½¿ç”¨é è¨­æ¨¡æ¿
        if not is_llm_configured():
            return await self._generate_template_analysis(query, analysis_domain)

        # æ§‹å»ºå°ˆæ¥­çš„æç¤ºè©
        prompt = self._build_analysis_prompt(query, analysis_domain, knowledge_context)

        try:
            # èª¿ç”¨ LLM ç”Ÿæˆåˆ†æ
            llm_response = await generate_llm_response(
                prompt,
                max_tokens=1200,
                temperature=0.3  # è¼ƒä½æº«åº¦ç¢ºä¿å°ˆæ¥­æ€§
            )

            # å¾Œè™•ç†ï¼šç¢ºä¿åŒ…å«å¿…è¦çš„é¢¨éšªè­¦èª
            analysis = self._post_process_analysis(llm_response.content)

            return analysis

        except Exception as e:
            self.logger.error(f"LLM generation failed: {e}")
            # é™ç´šåˆ°æ¨¡æ¿å›æ‡‰
            return await self._generate_template_analysis(query, analysis_domain)

    def _build_analysis_prompt(self,
                             query: str,
                             analysis_domain: str,
                             knowledge_context: str) -> str:
        """æ§‹å»ºå°ˆæ¥­çš„é‡‘èåˆ†ææç¤ºè©"""

        domain_name = self.analysis_domains.get(analysis_domain, "å¸‚å ´åˆ†æ")

        prompt = f"""ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„é‡‘èåˆ†æå¸«ï¼Œè«‹æ ¹æ“šä»¥ä¸‹è³‡è¨Šæä¾›å°ˆæ¥­çš„{domain_name}ï¼š

ç”¨æˆ¶æŸ¥è©¢ï¼š{query}

ç›¸é—œå¸‚å ´è³‡è¨Šï¼š
{knowledge_context}

è«‹æä¾›çµæ§‹åŒ–çš„åˆ†æå ±å‘Šï¼ŒåŒ…å«ï¼š

ğŸ“ˆ **{domain_name}å ±å‘Š**

ğŸ“Š **ç•¶å‰å¸‚å ´ç‹€æ³**
- åŸºæ–¼æä¾›çš„å¸‚å ´è³‡è¨Šé€²è¡Œå®¢è§€åˆ†æ
- çµåˆæ­·å²è¶¨å‹¢å’Œç•¶å‰ç‹€æ³

ğŸ’¡ **é—œéµç™¼ç¾**
1. **æ ¸å¿ƒè§€é»**ï¼šåŸºæ–¼æ•¸æ“šçš„å®¢è§€åˆ¤æ–·
2. **é¢¨éšªå› å­**ï¼šè­˜åˆ¥ä¸»è¦é¢¨éšªå’Œä¸ç¢ºå®šæ€§
3. **æ©Ÿæœƒåˆ†æ**ï¼šæ½›åœ¨çš„æŠ•è³‡æ©Ÿæœƒ

ğŸ“‹ **å°ˆæ¥­å»ºè­°**
- å…·é«”å¯åŸ·è¡Œçš„æŠ•è³‡ç­–ç•¥
- é©åˆçš„æŠ•è³‡æ™‚æ©Ÿå’Œæ–¹æ³•
- é¢¨éšªæ§åˆ¶æªæ–½

âš ï¸ **é¢¨éšªæé†’**
- æŠ•è³‡é¢¨éšªè­¦èª
- å¸‚å ´ä¸ç¢ºå®šæ€§æé†’

åˆ†æè¦æ±‚ï¼š
1. ä¿æŒå®¢è§€å°ˆæ¥­ï¼ŒåŸºæ–¼äº‹å¯¦å’Œæ•¸æ“š
2. é¿å…éåº¦æ¨‚è§€æˆ–æ‚²è§€çš„é æ¸¬
3. æä¾›å…·é«”å¯è¡Œçš„å»ºè­°
4. ä½¿ç”¨ç¹é«”ä¸­æ–‡å›æ‡‰
5. æ ¼å¼è¦æ¸…æ™°æ˜“è®€ï¼Œä½¿ç”¨é©ç•¶çš„ Markdown æ¨™è¨˜
"""

        return prompt

    async def _generate_template_analysis(self, query: str, analysis_domain: str) -> str:
        """ç”Ÿæˆæ¨¡æ¿åˆ†æï¼ˆLLM ä¸å¯ç”¨æ™‚çš„é™ç´šæ–¹æ¡ˆï¼‰"""
        domain_name = self.analysis_domains.get(analysis_domain, "å¸‚å ´åˆ†æ")

        return f"""ğŸ“ˆ **{domain_name}å ±å‘Š**

ğŸ“Š **ç•¶å‰å¸‚å ´ç‹€æ³**
- åŸºæ–¼æœ€æ–°å¸‚å ´è³‡è¨Šé€²è¡Œåˆ†æ
- è€ƒé‡ç¸½é«”ç¶“æ¿Ÿç’°å¢ƒå½±éŸ¿
- çµåˆæ­·å²æ•¸æ“šæ¯”è¼ƒ

ğŸ’¡ **é—œéµç™¼ç¾**
1. **è¶¨å‹¢åˆ¤æ–·**ï¼šæ ¹æ“šæŠ€è¡“æŒ‡æ¨™å’ŒåŸºæœ¬é¢æ•¸æ“šåˆ†æ
2. **é¢¨éšªè©•ä¼°**ï¼šè­˜åˆ¥ä¸»è¦é¢¨éšªå› å­å’Œä¸ç¢ºå®šæ€§
3. **æ©Ÿæœƒé»**ï¼šæ½›åœ¨æŠ•è³‡æ©Ÿæœƒå’Œé€²å ´æ™‚æ©Ÿ

ğŸ“‹ **æŠ•è³‡å»ºè­°**
- å»ºè­°æ¡ç”¨åˆ†æ•£æŠ•è³‡ç­–ç•¥
- å®šæœŸæª¢è¦–æŠ•è³‡çµ„åˆè¡¨ç¾
- æ ¹æ“šé¢¨éšªæ‰¿å—åº¦èª¿æ•´é…ç½®

âš ï¸ **é¢¨éšªæé†’**
- æŠ•è³‡æœ‰é¢¨éšªï¼Œéå¾€ç¸¾æ•ˆä¸ä»£è¡¨æœªä¾†è¡¨ç¾
- å»ºè­°åˆ†æ•£æŠ•è³‡ï¼Œæ§åˆ¶å–®ä¸€æ¨™çš„æŠ•è³‡æ¯”é‡
- å®šæœŸæª¢è¦–æŠ•è³‡çµ„åˆï¼Œé©æ™‚èª¿æ•´ç­–ç•¥

*æ³¨æ„ï¼šæ­¤ç‚ºé è¨­åˆ†ææ¨¡æ¿ï¼Œå»ºè­°é…ç½® LLM API ä»¥ç²å¾—æ›´è©³ç´°çš„å€‹äººåŒ–åˆ†æã€‚*
"""

    def _post_process_analysis(self, analysis: str) -> str:
        """å¾Œè™•ç†åˆ†æå…§å®¹ï¼Œç¢ºä¿åŒ…å«å¿…è¦è­¦èª"""

        # ç¢ºä¿åŒ…å«é¢¨éšªè­¦èª
        if "é¢¨éšªæé†’" not in analysis and "æŠ•è³‡é¢¨éšª" not in analysis:
            analysis += "\n\nâš ï¸ **æŠ•è³‡é¢¨éšªæé†’**\n- æŠ•è³‡æœ‰é¢¨éšªï¼Œè«‹è¬¹æ…è©•ä¼°å€‹äººè²¡å‹™ç‹€æ³\n- éå¾€ç¸¾æ•ˆä¸ä»£è¡¨æœªä¾†è¡¨ç¾\n- å»ºè­°åˆ†æ•£æŠ•è³‡ï¼Œä¸è¦é›†ä¸­å–®ä¸€æ¨™çš„"

        # ç¢ºä¿åŒ…å«å…è²¬è²æ˜
        if "æœ¬åˆ†æåƒ…ä¾›åƒè€ƒ" not in analysis:
            analysis += "\n\n*æœ¬åˆ†æåƒ…ä¾›åƒè€ƒï¼Œä¸æ§‹æˆæŠ•è³‡å»ºè­°ã€‚æŠ•è³‡æ±ºç­–è«‹è‡ªè¡Œåˆ¤æ–·ã€‚*"

        return analysis

    def _format_knowledge_context(self, knowledge_results: List[Dict]) -> str:
        """æ ¼å¼åŒ–çŸ¥è­˜æª¢ç´¢çµæœç‚ºä¸Šä¸‹æ–‡"""
        if not knowledge_results:
            return "æš«ç„¡ç›¸é—œå¸‚å ´è³‡è¨Š"

        context_parts = []
        for i, result in enumerate(knowledge_results[:6], 1):
            title = result.get('metadata', {}).get('title', f'å¸‚å ´è³‡è¨Š {i}')
            content = result.get('content', '')[:300]  # é™åˆ¶é•·åº¦
            context_parts.append(f"{i}. {title}: {content}")

        return "\n".join(context_parts)

    def _calculate_confidence(self, query: str, knowledge_results: List[Dict]) -> float:
        """è¨ˆç®—åˆ†æä¿¡å¿ƒåº¦"""
        base_confidence = 0.7

        # æ ¹æ“šæª¢ç´¢çµæœæ•¸é‡èª¿æ•´
        if len(knowledge_results) >= 5:
            base_confidence += 0.1
        elif len(knowledge_results) >= 3:
            base_confidence += 0.05

        # æ ¹æ“šæŸ¥è©¢æ˜ç¢ºåº¦èª¿æ•´
        if len(query) > 10 and any(keyword in query for keyword in
                                 ["åˆ†æ", "å»ºè­°", "æŠ•è³‡", "è‚¡ç¥¨", "åŸºé‡‘"]):
            base_confidence += 0.05

        # å¦‚æœä½¿ç”¨çœŸå¯¦ LLMï¼Œæé«˜ä¿¡å¿ƒåº¦
        if is_llm_configured():
            base_confidence += 0.1

        return min(base_confidence, 0.95)  # æœ€é«˜ 95%

    def get_analysis_capabilities(self) -> Dict[str, Any]:
        """å–å¾—åˆ†æèƒ½åŠ›æè¿°"""
        return {
            "supported_domains": list(self.analysis_domains.values()),
            "llm_configured": is_llm_configured(),
            "features": [
                "æŠ€è¡“åˆ†æ",
                "åŸºæœ¬é¢åˆ†æ",
                "å¸‚å ´åˆ†æ",
                "é¢¨éšªè©•ä¼°",
                "ç”¢æ¥­åˆ†æ"
            ],
            "data_sources": "RAG æª¢ç´¢ + å³æ™‚å¸‚å ´è³‡è¨Š"
        }