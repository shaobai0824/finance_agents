#!/usr/bin/env python3
"""
æª¢æŸ¥ç•¶å‰RAGç³»çµ±ä½¿ç”¨ç‹€æ…‹

ç¢ºèªï¼š
1. ç›®å‰ä½¿ç”¨çš„æ˜¯å“ªç¨®RAGç³»çµ±
2. è³‡æ–™åº«ä¸­çš„åˆ‡å‰²æ–¹å¼
3. æ˜¯å¦æœ‰èªæ„åˆ‡å‰²å’Œæ–‡ç« æ„ŸçŸ¥åŠŸèƒ½
"""

import sys
import json
from pathlib import Path

# æ·»åŠ å°ˆæ¡ˆè·¯å¾‘
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "src" / "main" / "python"))

from dotenv import load_dotenv
load_dotenv()

from src.main.python.rag.chroma_vector_store import ChromaVectorStore


def check_collection_details(collection_name: str):
    """æª¢æŸ¥ç‰¹å®šé›†åˆçš„è©³ç´°ä¿¡æ¯"""
    print(f"\n=== æª¢æŸ¥é›†åˆï¼š{collection_name} ===")

    try:
        vector_store = ChromaVectorStore(collection_name=collection_name)

        # ç²å–é›†åˆä¿¡æ¯
        collection = vector_store.collection
        document_count = collection.count()

        print(f"æ–‡æª”ç¸½æ•¸ï¼š{document_count}")

        if document_count > 0:
            # å–æ¨£åˆ†æå‰5å€‹æ–‡æª”
            results = collection.get(limit=5, include=['documents', 'metadatas'])

            print(f"\nğŸ“„ æ–‡æª”æ¨£æœ¬åˆ†æï¼š")
            for i, (doc, metadata) in enumerate(zip(results['documents'], results['metadatas'])):
                print(f"\n--- æ–‡æª” {i+1} ---")
                print(f"é•·åº¦ï¼š{len(doc)} å­—ç¬¦")
                print(f"å…ƒæ•¸æ“šï¼š{json.dumps(metadata, ensure_ascii=False, indent=2)}")
                print(f"å…§å®¹é è¦½ï¼š{doc[:100]}...")

                # åˆ†æåˆ‡å‰²æ–¹å¼
                if 'ã€‚' in doc:
                    sentence_count = doc.count('ã€‚')
                    print(f"å¥å­æ•¸é‡ï¼š{sentence_count}")

                # æª¢æŸ¥æ˜¯å¦æœ‰èªæ„åˆ‡å‰²æ¨™è¨˜
                if metadata:
                    has_semantic = any(key in str(metadata).lower() for key in ['semantic', 'boundary', 'coherence'])
                    has_article_id = 'original_document_id' in metadata or 'article_id' in metadata
                    print(f"èªæ„åˆ‡å‰²æ¨™è¨˜ï¼š{'âœ…' if has_semantic else 'âŒ'}")
                    print(f"æ–‡ç« IDæ¨™è¨˜ï¼š{'âœ…' if has_article_id else 'âŒ'}")

        return document_count > 0

    except Exception as e:
        print(f"éŒ¯èª¤ï¼š{e}")
        return False


def analyze_chunking_method():
    """åˆ†æç•¶å‰ä½¿ç”¨çš„åˆ‡å‰²æ–¹æ³•"""
    print("\nğŸ” åˆ†æåˆ‡å‰²æ–¹æ³•")
    print("-" * 40)

    # æª¢æŸ¥æ˜¯å¦æœ‰èªæ„åˆ‡å‰²ç›¸é—œæª”æ¡ˆ
    semantic_files = [
        "src/main/python/rag/semantic_chunking.py",
        "src/main/python/rag/enhanced_vector_store.py",
        "src/main/python/rag/chunking_config.py"
    ]

    print("èªæ„åˆ‡å‰²ç³»çµ±æª”æ¡ˆæª¢æŸ¥ï¼š")
    for file_path in semantic_files:
        full_path = project_root / file_path
        exists = full_path.exists()
        print(f"  {file_path}: {'âœ…' if exists else 'âŒ'}")

    # æª¢æŸ¥ä¸»è¦ç³»çµ±ä½¿ç”¨çš„é¡åˆ¥
    print(f"\nä¸»è¦ç³»çµ±ä½¿ç”¨æª¢æŸ¥ï¼š")

    # æª¢æŸ¥ API main.py
    api_main_path = project_root / "src/main/python/api/main.py"
    if api_main_path.exists():
        with open(api_main_path, 'r', encoding='utf-8') as f:
            api_content = f.read()

        if 'EnhancedVectorStore' in api_content:
            print("  API ä¸»ç³»çµ±ï¼šâœ… ä½¿ç”¨ EnhancedVectorStore (æ–‡ç« æ„ŸçŸ¥RAG)")
        elif 'ChromaVectorStore' in api_content:
            print("  API ä¸»ç³»çµ±ï¼šğŸŸ¡ ä½¿ç”¨ ChromaVectorStore (å‚³çµ±RAG)")
        else:
            print("  API ä¸»ç³»çµ±ï¼šâŒ æœªæ‰¾åˆ°å‘é‡å­˜å„²ä½¿ç”¨")


def check_database_collections():
    """æª¢æŸ¥è³‡æ–™åº«ä¸­çš„æ‰€æœ‰é›†åˆ"""
    print("\nğŸ“š è³‡æ–™åº«é›†åˆæª¢æŸ¥")
    print("-" * 40)

    # å¸¸è¦‹çš„é›†åˆåç¨±
    collection_names = [
        "finance_knowledge",
        "finance_knowledge_optimal",
        "financial_news",
        "test_semantic_chunking",
        "enhanced_test",
        "traditional_test"
    ]

    active_collections = []

    for collection_name in collection_names:
        try:
            has_data = check_collection_details(collection_name)
            if has_data:
                active_collections.append(collection_name)
        except Exception as e:
            print(f"é›†åˆ {collection_name} æª¢æŸ¥å¤±æ•—ï¼š{e}")

    return active_collections


def main():
    """ä¸»è¦æª¢æŸ¥å‡½æ•¸"""
    print("ğŸ” RAGç³»çµ±ç‹€æ…‹æª¢æŸ¥å ±å‘Š")
    print("=" * 60)

    # 1. åˆ†æåˆ‡å‰²æ–¹æ³•
    analyze_chunking_method()

    # 2. æª¢æŸ¥è³‡æ–™åº«é›†åˆ
    active_collections = check_database_collections()

    # 3. ç¸½çµå ±å‘Š
    print("\n" + "=" * 60)
    print("ğŸ“‹ ç¸½çµå ±å‘Š")
    print("=" * 60)

    print(f"\nğŸ¯ ç•¶å‰ç³»çµ±ç‹€æ…‹ï¼š")

    # æª¢æŸ¥ä¸»è¦APIä½¿ç”¨çš„ç³»çµ±
    api_main_path = project_root / "src/main/python/api/main.py"
    if api_main_path.exists():
        with open(api_main_path, 'r', encoding='utf-8') as f:
            api_content = f.read()

        if 'EnhancedVectorStore' in api_content:
            print("  âœ… ä¸»ç³»çµ±å·²å‡ç´šç‚ºæ–‡ç« æ„ŸçŸ¥RAG (EnhancedVectorStore)")
            rag_type = "Article-Aware Context RAG"
        elif 'ChromaVectorStore' in api_content:
            print("  ğŸŸ¡ ä¸»ç³»çµ±ä»ä½¿ç”¨å‚³çµ±RAG (ChromaVectorStore)")
            rag_type = "Traditional RAG"
            if 'finance_knowledge_optimal' in api_content:
                print("  ğŸ“ ä½¿ç”¨æœ€ä½³åŒ–é›†åˆ (finance_knowledge_optimal)")
        else:
            print("  âŒ ä¸»ç³»çµ±é…ç½®ä¸æ˜")
            rag_type = "æœªçŸ¥"

    print(f"\nğŸ“Š æ´»èºçš„è³‡æ–™åº«é›†åˆï¼š")
    if active_collections:
        for collection in active_collections:
            print(f"  â€¢ {collection}")

        main_collection = "finance_knowledge_optimal"
        if main_collection in active_collections:
            print(f"\nğŸ¯ ä¸»è¦ä½¿ç”¨çš„é›†åˆï¼š{main_collection}")
            print("  é€™å€‹é›†åˆä½¿ç”¨å¥å­æ„ŸçŸ¥åˆ‡å‰² (400å­—ç¬¦ç›®æ¨™ï¼Œé‡ç–Š50å­—ç¬¦)")
    else:
        print("  âŒ æ²’æœ‰æ‰¾åˆ°æ´»èºçš„è³‡æ–™åº«é›†åˆ")

    print(f"\nğŸ¤” å›ç­”æ‚¨çš„å•é¡Œï¼š")
    print(f"1. ç›®å‰ä½¿ç”¨çš„æ–¹å¼ï¼š{rag_type}")

    if rag_type == "Traditional RAG":
        print("2. è³‡æ–™åº«å…§å®¹ï¼šä½¿ç”¨å‚³çµ±çš„å¥å­æ„ŸçŸ¥åˆ‡å‰²")
        print("   - æ¯å€‹chunkç´„400å­—ç¬¦")
        print("   - åœ¨å¥è™Ÿè™•åˆ†å‰²")
        print("   - æœ‰é©åº¦é‡ç–Š(50å­—ç¬¦)")
        print("   - âŒ æ²’æœ‰èªæ„é‚Šç•Œæª¢æ¸¬")
        print("   - âŒ æ²’æœ‰æ–‡ç« ä¸Šä¸‹æ–‡ä¿æŒ")

        print("3. æœç´¢æ–¹å¼ï¼š")
        print("   - å‘é‡ç›¸ä¼¼åº¦æœç´¢")
        print("   - è¿”å›æœ€ç›¸é—œçš„å€‹åˆ¥chunks")
        print("   - âŒ ä¸æœƒè‡ªå‹•åŒ…å«åŒä¸€ç¯‡æ–‡ç« çš„å…¶ä»–chunks")

        print("\nğŸ’¡ å‡ç´šå»ºè­°ï¼š")
        print("   å¦‚æœè¦å‡ç´šåˆ°æ–‡ç« æ„ŸçŸ¥RAGï¼š")
        print("   1. éœ€è¦æ›´æ–° API main.py ä½¿ç”¨ EnhancedVectorStore")
        print("   2. éœ€è¦é‡æ–°è¼‰å…¥è³‡æ–™ä»¥æ·»åŠ èªæ„åˆ‡å‰²æ¨™è¨˜")
        print("   3. æˆ–ä¿æŒç¾æœ‰è³‡æ–™ï¼Œåªæ”¹è®Šæœç´¢æ–¹å¼")

    elif rag_type == "Article-Aware Context RAG":
        print("2. è³‡æ–™åº«å…§å®¹ï¼šä½¿ç”¨èªæ„é‚Šç•Œåˆ‡å‰²")
        print("   - åŸºæ–¼å¥å­embeddingç›¸ä¼¼åº¦åˆ‡å‰²")
        print("   - ä¿æŒæ–‡ç« IDé—œè¯")
        print("   - æœ‰èªæ„ä¸€è‡´æ€§è©•åˆ†")

        print("3. æœç´¢æ–¹å¼ï¼š")
        print("   - èªæ„ç›¸ä¼¼åº¦æœç´¢")
        print("   - è‡ªå‹•åŒ…å«åŒç¯‡æ–‡ç« çš„ç›¸é—œchunks")
        print("   - æä¾›å®Œæ•´çš„æ–‡ç« ä¸Šä¸‹æ–‡")


if __name__ == "__main__":
    main()