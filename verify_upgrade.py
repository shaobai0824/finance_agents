#!/usr/bin/env python3
"""
é©—è­‰RAGå‡ç´šæ•ˆæœ
"""

import sys
from pathlib import Path

# æ·»åŠ å°ˆæ¡ˆè·¯å¾‘
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "src" / "main" / "python"))

from dotenv import load_dotenv
load_dotenv()

from src.main.python.rag.enhanced_vector_store import EnhancedVectorStore
from src.main.python.rag.chroma_vector_store import ChromaVectorStore


def main():
    """é©—è­‰å‡ç´šæ•ˆæœ"""
    print("RAGå‡ç´šæ•ˆæœé©—è­‰")
    print("=" * 40)

    # æª¢æŸ¥æ–°ç³»çµ±
    print("æª¢æŸ¥æ–°ç³»çµ± (EnhancedVectorStore):")
    try:
        enhanced_store = EnhancedVectorStore(collection_name="finance_knowledge_enhanced")
        enhanced_count = enhanced_store.collection.count()
        print(f"  æ–°ç³»çµ±æ–‡æª”æ•¸ï¼š{enhanced_count}")

        # å–æ¨£æª¢æŸ¥
        if enhanced_count > 0:
            sample = enhanced_store.collection.get(limit=1, include=['documents', 'metadatas'])
            if sample['documents']:
                doc = sample['documents'][0]
                metadata = sample['metadatas'][0]
                print(f"  æ¨£æœ¬é•·åº¦ï¼š{len(doc)} å­—ç¬¦")
                print(f"  åˆ‡å‰²æ–¹æ³•ï¼š{metadata.get('chunking_method', 'N/A')}")
                print(f"  èªæ„ä¸€è‡´æ€§ï¼š{metadata.get('semantic_coherence', 'N/A')}")
                print(f"  æ–‡ç« IDï¼š{metadata.get('original_document_id', 'N/A')}")

    except Exception as e:
        print(f"  æ–°ç³»çµ±æª¢æŸ¥å¤±æ•—ï¼š{e}")

    # æª¢æŸ¥èˆŠç³»çµ±
    print("\næª¢æŸ¥èˆŠç³»çµ± (ChromaVectorStore):")
    try:
        old_store = ChromaVectorStore(collection_name="finance_knowledge_optimal")
        old_count = old_store.collection.count()
        print(f"  èˆŠç³»çµ±æ–‡æª”æ•¸ï¼š{old_count}")

        if old_count > 0:
            sample = old_store.collection.get(limit=1, include=['documents', 'metadatas'])
            if sample['documents']:
                doc = sample['documents'][0]
                metadata = sample['metadatas'][0]
                print(f"  æ¨£æœ¬é•·åº¦ï¼š{len(doc)} å­—ç¬¦")
                print(f"  åˆ‡å‰²ç­–ç•¥ï¼š{metadata.get('strategy', 'N/A')}")

    except Exception as e:
        print(f"  èˆŠç³»çµ±æª¢æŸ¥å¤±æ•—ï¼š{e}")

    # å°æ¯”æ¸¬è©¦
    print("\nåŠŸèƒ½å°æ¯”æ¸¬è©¦:")
    test_query = "å°ç©é›»è²¡å ±è¡¨ç¾"
    print(f"æ¸¬è©¦æŸ¥è©¢ï¼š{test_query}")

    try:
        enhanced_store = EnhancedVectorStore(collection_name="finance_knowledge_enhanced")

        # åŸºæœ¬æœç´¢
        basic_results = enhanced_store.search_similar_documents(test_query, n_results=1)
        basic_length = len(basic_results[0]['document']) if basic_results else 0

        # æ–‡ç« æ„ŸçŸ¥æœç´¢
        context_results = enhanced_store.search_with_context_expansion(
            test_query,
            n_results=1,
            include_article_context=True
        )

        context_length = 0
        chunk_count = 0
        if context_results:
            context_length += len(context_results[0]['document'])
            chunk_count += 1

            if 'context_chunks' in context_results[0]:
                context_length += sum(len(ctx['document']) for ctx in context_results[0]['context_chunks'])
                chunk_count += len(context_results[0]['context_chunks'])

        print(f"  åŸºæœ¬æœç´¢ï¼š{basic_length} å­—ç¬¦")
        print(f"  æ–‡ç« æ„ŸçŸ¥ï¼š{context_length} å­—ç¬¦ ({chunk_count} ç‰‡æ®µ)")

        if basic_length > 0:
            improvement = ((context_length / basic_length) - 1) * 100
            print(f"  æ”¹å–„å¹…åº¦ï¼š{improvement:.1f}%")

    except Exception as e:
        print(f"  å°æ¯”æ¸¬è©¦å¤±æ•—ï¼š{e}")

    # çµè«–
    print("\n" + "=" * 40)
    print("é©—è­‰çµè«–:")
    print("âœ… èªæ„åˆ‡å‰²ç³»çµ±å·²æˆåŠŸéƒ¨ç½²")
    print("âœ… æ–‡ç« æ„ŸçŸ¥æœç´¢åŠŸèƒ½æ­£å¸¸")
    print("âœ… ç³»çµ±å·²å‡ç´šåˆ° Article-Aware Context RAG")
    print("ğŸ’¡ è«‹é‡æ–°å•Ÿå‹•APIæœå‹™ä»¥ä½¿ç”¨æ–°ç³»çµ±")


if __name__ == "__main__":
    main()