# ğŸ“… æ–°èçˆ¬èŸ²æ’ç¨‹è¨­å®šæŒ‡å—

## ğŸ¯ å¿«é€Ÿé–‹å§‹

### æ–¹æ¡ˆé¸æ“‡

| ä½¿ç”¨å ´æ™¯ | æ¨è–¦æ–¹æ¡ˆ | è¨­å®šæ­¥é©Ÿ |
|---------|---------|---------|
| **æ¸¬è©¦/é–‹ç™¼** | APScheduler | åŸ·è¡Œ Python è…³æœ¬ |
| **Windows ç”Ÿç”¢** | Windows å·¥ä½œæ’ç¨‹å™¨ | åŸ·è¡Œ setup_windows_scheduler.bat |
| **Linux ç”Ÿç”¢** | systemd + cron | æ‰‹å‹•è¨­å®š systemd service |

---

## ğŸªŸ æ–¹æ¡ˆ 1ï¼šWindows å·¥ä½œæ’ç¨‹å™¨ï¼ˆæ¨è–¦ï¼‰

### å„ªé»
- âœ… Windows å…§å»ºï¼Œç„¡éœ€é¡å¤–è»Ÿé«”
- âœ… é–‹æ©Ÿè‡ªå‹•å•Ÿå‹•
- âœ… ç³»çµ±ç´šæ’ç¨‹ï¼Œç©©å®šå¯é 
- âœ… GUI ç®¡ç†ä»‹é¢

### è¨­å®šæ­¥é©Ÿ

#### 1. è‡ªå‹•è¨­å®šï¼ˆæ¨è–¦ï¼‰

```batch
# å³éµé»æ“Šï¼Œé¸æ“‡ã€Œä»¥ç³»çµ±ç®¡ç†å“¡èº«åˆ†åŸ·è¡Œã€
setup_windows_scheduler.bat
```

ç³»çµ±æœƒè©¢å•ï¼š
- åŸ·è¡Œå°æ™‚ (0-23ï¼Œé è¨­ 9)
- åŸ·è¡Œåˆ†é˜ (0-59ï¼Œé è¨­ 0)

#### 2. æ‰‹å‹•è¨­å®š

1. é–‹å•Ÿã€Œå·¥ä½œæ’ç¨‹å™¨ã€(Task Scheduler)
2. é»æ“Šã€Œå»ºç«‹åŸºæœ¬å·¥ä½œã€
3. è¨­å®šï¼š
   - åç¨±ï¼šCnyesNewsScraper
   - è§¸ç™¼ç¨‹åºï¼šæ¯æ—¥
   - æ™‚é–“ï¼š09:00ï¼ˆæˆ–ä½ æƒ³è¦çš„æ™‚é–“ï¼‰
   - å‹•ä½œï¼šå•Ÿå‹•ç¨‹å¼
   - ç¨‹å¼ï¼š`run_daily_scrape.bat` çš„å®Œæ•´è·¯å¾‘

### ç®¡ç†æŒ‡ä»¤

```batch
# æŸ¥çœ‹æ’ç¨‹ç‹€æ…‹
schtasks /query /tn "CnyesNewsScraper"

# ç«‹å³åŸ·è¡Œä¸€æ¬¡
schtasks /run /tn "CnyesNewsScraper"

# åœç”¨æ’ç¨‹
schtasks /change /tn "CnyesNewsScraper" /disable

# å•Ÿç”¨æ’ç¨‹
schtasks /change /tn "CnyesNewsScraper" /enable

# åˆªé™¤æ’ç¨‹
schtasks /delete /tn "CnyesNewsScraper" /f
```

### æŸ¥çœ‹æ—¥èªŒ

```batch
# æ—¥èªŒä½ç½®
logs\scraper_YYYYMMDD.log

# ç¯„ä¾‹
logs\scraper_20251002.log
```

---

## ğŸ æ–¹æ¡ˆ 2ï¼šAPSchedulerï¼ˆPython åŸç”Ÿï¼‰

### å„ªé»
- âœ… å·²ç¶“å¯¦ä½œå®Œæˆ
- âœ… Python ç¨‹å¼ç¢¼æ§åˆ¶
- âœ… éˆæ´»é…ç½®

### ç¼ºé»
- âŒ éœ€è¦ä¿æŒ Python é€²ç¨‹é‹è¡Œ
- âŒ é—œæ©Ÿ/é‡å•Ÿæœƒåœæ­¢

### ä½¿ç”¨æ–¹æ³•

#### åŸ·è¡Œä¸€æ¬¡ï¼ˆæ¸¬è©¦ï¼‰
```bash
python src/main/python/etl/news_scheduler.py --mode once --articles 10
```

#### å•Ÿå‹•æ’ç¨‹ï¼ˆéœ€ä¿æŒé‹è¡Œï¼‰
```bash
# æ¯å¤©æ—©ä¸Š 9:00ï¼Œæ¯å€‹åˆ†é¡ 20 ç¯‡
python src/main/python/etl/news_scheduler.py --mode schedule --hour 9 --minute 0 --articles 20
```

#### æŸ¥çœ‹æ­·å²
```bash
python src/main/python/etl/news_scheduler.py --mode history
```

---

## ğŸ§ æ–¹æ¡ˆ 3ï¼šLinux systemdï¼ˆLinux ç”Ÿç”¢ç’°å¢ƒï¼‰

### 1. å‰µå»º systemd service æª”æ¡ˆ

```bash
sudo nano /etc/systemd/system/cnyes-scraper.service
```

å…§å®¹ï¼š
```ini
[Unit]
Description=Cnyes News Scraper
After=network.target

[Service]
Type=simple
User=your_username
WorkingDirectory=/path/to/project
Environment="PATH=/path/to/project/finance_agents_env/bin"
ExecStart=/path/to/project/finance_agents_env/bin/python src/main/python/etl/news_scheduler.py --mode once --articles 20
Restart=on-failure

[Install]
WantedBy=multi-user.target
```

### 2. å‰µå»º cron å®šæ™‚ä»»å‹™

```bash
crontab -e
```

æ·»åŠ ï¼š
```bash
# æ¯å¤©æ—©ä¸Š 9:00 åŸ·è¡Œ
0 9 * * * systemctl start cnyes-scraper.service
```

### 3. ç®¡ç†æŒ‡ä»¤

```bash
# å•Ÿç”¨æœå‹™
sudo systemctl enable cnyes-scraper.service

# ç«‹å³åŸ·è¡Œ
sudo systemctl start cnyes-scraper.service

# æŸ¥çœ‹ç‹€æ…‹
sudo systemctl status cnyes-scraper.service

# æŸ¥çœ‹æ—¥èªŒ
sudo journalctl -u cnyes-scraper.service -f
```

---

## ğŸ³ æ–¹æ¡ˆ 4ï¼šDocker + Cronï¼ˆå®¹å™¨åŒ–éƒ¨ç½²ï¼‰

### 1. å‰µå»º Dockerfile

```dockerfile
FROM python:3.11-slim

WORKDIR /app

# å®‰è£ç³»çµ±ä¾è³´
RUN apt-get update && apt-get install -y \
    chromium \
    chromium-driver \
    cron \
    && rm -rf /var/lib/apt/lists/*

# è¤‡è£½å°ˆæ¡ˆ
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

# è¨­å®š cron
RUN echo "0 9 * * * cd /app && python src/main/python/etl/news_scheduler.py --mode once --articles 20 >> /app/logs/cron.log 2>&1" > /etc/cron.d/scraper-cron
RUN chmod 0644 /etc/cron.d/scraper-cron
RUN crontab /etc/cron.d/scraper-cron

CMD ["cron", "-f"]
```

### 2. ä½¿ç”¨ Docker Compose

```yaml
version: '3.8'

services:
  scraper:
    build: .
    container_name: cnyes-scraper
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./chroma_db:/app/chroma_db
    env_file:
      - .env
    restart: unless-stopped
```

### 3. éƒ¨ç½²

```bash
# æ§‹å»ºä¸¦å•Ÿå‹•
docker-compose up -d

# æŸ¥çœ‹æ—¥èªŒ
docker-compose logs -f

# æ‰‹å‹•åŸ·è¡Œä¸€æ¬¡
docker-compose exec scraper python src/main/python/etl/news_scheduler.py --mode once --articles 20
```

---

## ğŸ”§ çˆ¬èŸ²æ¸¬è©¦èˆ‡èª¿è©¦

### æ¸¬è©¦å‰æº–å‚™

1. **å®‰è£ ChromeDriver**ï¼ˆSelenium éœ€è¦ï¼‰

```bash
# æ–¹æ³• 1ï¼šä½¿ç”¨ webdriver-managerï¼ˆæ¨è–¦ï¼‰
pip install webdriver-manager

# æ–¹æ³• 2ï¼šæ‰‹å‹•ä¸‹è¼‰
# ä¸‹è¼‰ï¼šhttps://chromedriver.chromium.org/
# æ”¾ç½®ï¼šC:\Program Files\ChromeDriver\chromedriver.exe
# æ·»åŠ åˆ° PATH
```

2. **é©—è­‰ç’°å¢ƒ**

```bash
# æ¸¬è©¦ ChromeDriver
chromedriver --version

# æ¸¬è©¦ Python ç’°å¢ƒ
python -c "from selenium import webdriver; print('OK')"
```

### æ¸¬è©¦æ­¥é©Ÿ

#### 1. å¿«é€Ÿæ¸¬è©¦ï¼ˆ1ç¯‡æ–‡ç« ï¼‰

```bash
python test_auto_scraper.py
```

#### 2. å®Œæ•´æ¸¬è©¦ï¼ˆæŒ‡å®šæ–‡ç« æ•¸ï¼‰

```bash
# æ¯å€‹åˆ†é¡ 5 ç¯‡
python src/main/python/etl/news_scheduler.py --mode once --articles 5
```

#### 3. æª¢æŸ¥çµæœ

```bash
# æŸ¥çœ‹æ—¥èªŒ
type logs\news_scheduler.log

# æŸ¥çœ‹åŸ·è¡Œæ­·å²
python src/main/python/etl/news_scheduler.py --mode history

# æª¢æŸ¥è³‡æ–™åº«
python diagnose_rag.py
```

### å¸¸è¦‹å•é¡Œæ’é™¤

#### å•é¡Œ 1ï¼šChromeDriver éŒ¯èª¤

**éŒ¯èª¤è¨Šæ¯**ï¼š
```
selenium.common.exceptions.WebDriverException: 'chromedriver' executable needs to be in PATH
```

**è§£æ±ºæ–¹æ³•**ï¼š
```bash
# å®‰è£ webdriver-manager
pip install webdriver-manager

# ä¿®æ”¹çˆ¬èŸ²é…ç½®ï¼ˆå¦‚éœ€è¦ï¼‰
```

#### å•é¡Œ 2ï¼šçˆ¬å– 0 ç¯‡æ–‡ç« 

**å¯èƒ½åŸå› **ï¼š
1. ç¶²ç«™çµæ§‹æ”¹è®Šï¼ˆéœ€æ›´æ–°é¸æ“‡å™¨ï¼‰
2. IP è¢«å°é–ï¼ˆéœ€è¦ä»£ç†ï¼‰
3. Selenium é…ç½®å•é¡Œ

**èª¿è©¦æ­¥é©Ÿ**ï¼š
```bash
# 1. æ¸¬è©¦ç¶²ç«™æ˜¯å¦å¯è¨ªå•
curl -I https://news.cnyes.com

# 2. æª¢æŸ¥ Selenium æ—¥èªŒ
# æŸ¥çœ‹çˆ¬èŸ²æ—¥èªŒä¸­çš„è©³ç´°éŒ¯èª¤

# 3. æ‰‹å‹•æ¸¬è©¦é¸æ“‡å™¨ï¼ˆä½¿ç”¨ç€è¦½å™¨é–‹ç™¼è€…å·¥å…·ï¼‰
```

#### å•é¡Œ 3ï¼šè¨˜æ†¶é«”ä¸è¶³

**è§£æ±ºæ–¹æ³•**ï¼š
```python
# èª¿æ•´é…ç½®
scraper_config = {
    'articles_per_category': 10,  # æ¸›å°‘çˆ¬å–æ•¸é‡
    'request_delay': (3, 5),      # å¢åŠ å»¶é²
}
```

---

## ğŸ“Š ç›£æ§èˆ‡ç¶­è­·

### æ—¥èªŒä½ç½®

```
logs/
â”œâ”€â”€ news_scheduler.log         # æ’ç¨‹å™¨æ—¥èªŒ
â”œâ”€â”€ scraper_20251002.log       # æ¯æ—¥çˆ¬èŸ²æ—¥èªŒ
â””â”€â”€ execution_history.json     # åŸ·è¡Œæ­·å²
```

### å®šæœŸæª¢æŸ¥

```bash
# æ¯é€±æª¢æŸ¥
1. æŸ¥çœ‹æ—¥èªŒï¼šæœ‰ç„¡éŒ¯èª¤
2. æª¢æŸ¥è³‡æ–™åº«ï¼šè³‡æ–™æ˜¯å¦å¢é•·
3. æ¸¬è©¦æª¢ç´¢ï¼šRAG æ˜¯å¦æ­£å¸¸

# æŒ‡ä»¤
dir logs\scraper_*.log
python diagnose_rag.py
```

### èª¿æ•´é…ç½®

ä¿®æ”¹ `run_daily_scrape.bat`ï¼š
```batch
REM èª¿æ•´çˆ¬å–æ•¸é‡
"%PYTHON_ENV%" src\main\python\etl\news_scheduler.py --mode once --articles 30

REM ä½¿ç”¨ä¸åŒé›†åˆ
"%PYTHON_ENV%" src\main\python\etl\news_scheduler.py --mode once --articles 20 --collection my_collection
```

---

## ğŸ¯ æœ€ä½³å¯¦è¸

### 1. é–‹ç™¼ç’°å¢ƒ
- ä½¿ç”¨ APScheduler æ¸¬è©¦
- å°æ‰¹é‡çˆ¬å–ï¼ˆ5-10 ç¯‡/åˆ†é¡ï¼‰
- é »ç¹æŸ¥çœ‹æ—¥èªŒ

### 2. ç”Ÿç”¢ç’°å¢ƒ
- Windowsï¼šå·¥ä½œæ’ç¨‹å™¨
- Linuxï¼šsystemd + cron
- Dockerï¼šå®¹å™¨åŒ–éƒ¨ç½²

### 3. çˆ¬èŸ²ç¦®å„€
- è¨­å®šåˆç†å»¶é²ï¼ˆ2-5ç§’ï¼‰
- é™åˆ¶ä¸¦ç™¼è«‹æ±‚
- éµå®ˆ robots.txt
- é¿å…é«˜å³°æ™‚æ®µ

### 4. è³‡æ–™å“è³ª
- å®šæœŸæª¢æŸ¥å»é‡æ•ˆæœ
- ç›£æ§è³‡æ–™å¢é•·é€Ÿåº¦
- é©—è­‰ RAG æª¢ç´¢å“è³ª

---

## ğŸ“ æŠ€è¡“æ”¯æ´

### å•é¡Œå›å ±

é‡åˆ°å•é¡Œæ™‚ï¼Œè«‹æä¾›ï¼š
1. éŒ¯èª¤è¨Šæ¯ï¼ˆå®Œæ•´ï¼‰
2. æ—¥èªŒæª”æ¡ˆï¼ˆç›¸é—œéƒ¨åˆ†ï¼‰
3. åŸ·è¡Œç’°å¢ƒï¼ˆOSã€Python ç‰ˆæœ¬ï¼‰
4. åŸ·è¡ŒæŒ‡ä»¤

### ç›¸é—œæ–‡ä»¶

- çˆ¬èŸ²å¯¦ä½œï¼š`src/main/python/etl/scrapers/cnyes_auto_scraper.py`
- æ•´åˆæµç¨‹ï¼š`src/main/python/etl/auto_news_pipeline.py`
- æ’ç¨‹å™¨ï¼š`src/main/python/etl/news_scheduler.py`
